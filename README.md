# ğŸ§  AIChat For My Docs

A powerful Retrieval-Augmented Generation (RAG) Python app that lets you load your own documents, search intelligently using hybrid/semantic/query expansion methods, and get accurate natural language answers powered by LLMs.

## ğŸš€ Features

- Load and split Markdown (`.md`) documents
- Store embeddings in a persistent **Chroma DB**
- Use **hybrid retrieval** (BM25 + vector search)
- Support for **semantic reranking**
- Simple **query expansion** logic (Word2Vec/embedding-based)
- Powered by ğŸ¤— `sentence-transformers` + OpenRouter LLMs
- Interactive CLI to ask questions and receive smart answers

## ğŸ“ Project Structure

.
â”œâ”€â”€ aicfmd_v1.py # Main RAG system
â”œâ”€â”€ data/ # Directory for your .md files
â”œâ”€â”€ chroma/ # Persisted Chroma DB
â”œâ”€â”€ .env # Contains your API key for OpenRouter
â”œâ”€â”€ README.md # You're reading it

perl
Copy
Edit

## ğŸ§° Requirements

Make sure to install the dependencies:

```bash
pip install -r requirements.txt
Minimal requirements.txt:

langchain
langchain-community
langchain-huggingface
chromadb
openai
python-dotenv
sentence-transformers
```
ğŸ”‘ .env Configuration
Create a .env file in the root folder:


DEEPSEEK_API_KEY=your_openrouter_api_key
You can get a free OpenRouter key from https://openrouter.ai/

ğŸ“¥ Adding Your Documents
Place your .md files inside the data/ folder.

Example:

kotlin

data/
â””â”€â”€ alice_in_wonderland.md
ğŸ§ª Running the App
Run the script from terminal:

```bash

python aicfmd_v1.py
```
You'll see:

```bash

Creating semantic database...
ğŸ§  Ask anything! (type 'exit' to quit)
ğŸ“ Your question:
```
Example Interaction
```vbnet

ğŸ“ Your question: What is Alice doing in the story?
--- Result 1 ---
Content Snippet: Alice was not a bit hurt, and she jumped up on to her feet in a moment...

ğŸ’¬ Answer: Alice is exploring Wonderland, following the White Rabbit and facing many surreal challenges...

ğŸ“ Your question: exit
ğŸ‘‹ Exiting. Goodbye!`
```
âš™ï¸ Search Modes
By default, the app uses "semantic_with_rerank" search. You can easily change this in aicfmd_v1.py:

```python

documents = rag_system.make_query(query=query, method="hybrid")
```
Supported methods:

semantic_with_rerank

hybrid

query_expansion

basic (raw vector search)

ğŸ§  Future Ideas
Add PDF parsing with automatic Markdown conversion

Support chat history with memory

Web frontend using Streamlit or Flask

Plug in multilingual embeddings (e.g., LaBSE or multilingual MPNet)

ğŸ‘¤ Author
Created by Ouday Messaadi
